import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow.keras as keras
import keras.backend as K
from keras.optimizers import Adam
import os
from IPython.display import display
import util
%autosave 5


possibleConvFilters = util.createRangeFromMidpoint(38,38)

possibleConvAndPoolLayers = util.createRangeFromMidpoint(5,5)

possibleNumberOfFCLayers = util.createRangeFromMidpoint(22,17)
possibleNumberOfNeuronsPerFCLayer = util.createRangeFromMidpoint(9,9)

possibleNumberOfEpochs = util.createRangeFromMidpoint(40,28)

lastBestDropoutRate = 0.710042	
lastBestAdamLearningRate = 0.000350	
lastBestL2 = 71.708797	

trial = 20


train = util.loadData("training")
dev,test = util.loadData("testing",.5)

choose = np.random.choice

n_convFilters = []
n_convAndPoolLayers = []
n_FCLayers = []
n_NeuronsPerFCLayers = []
n_Epochs = []
dropoutRates = []
adamLearningRates = []
L2Rates = []
trainScores = []
devScores = []

lastTrialForNotebook = trial + 10

while trial < lastTrialForNotebook:
    convFilters = choose(possibleConvFilters)

    convAndPoolLayers = choose(possibleConvAndPoolLayers)
    convAndPoolLayers = min([convAndPoolLayers,6])

    numberOfFCLayers = choose(possibleNumberOfFCLayers)
    numberOfNeuronsPerFCLayer = choose(possibleNumberOfNeuronsPerFCLayer)

    numberOfEpochs = choose(possibleNumberOfEpochs)
    
    dropoutRate = (np.random.rand() + lastBestDropoutRate)/2
    adamLearningRate = util.generateAdamLearningRate(lastBestAdamLearningRate)
    L2Rate = util.generateL2(lastBestL2)
    

    model = util.createModel(convFilters, convAndPoolLayers,numberOfFCLayers, numberOfNeuronsPerFCLayer, dropoutRate, adamLearningRate, L2Rate)

    model.fit(train,epochs=numberOfEpochs,verbose=0)

    model_path = f'../Models/FlipDetectionModelTrials/fd_model_{trial}.h5'
    model.save(model_path)
    model_size = os.path.getsize(model_path) / (1024 * 1024)
    if model_size < 40:
        print()
        print('trainScore')
        trainScore = model.evaluate(train)[1]
        print('devScore')
        devScore = model.evaluate(dev)[1]

        n_convFilters.append(convFilters)
        n_convAndPoolLayers.append(convAndPoolLayers)
        n_FCLayers.append(numberOfFCLayers)
        n_NeuronsPerFCLayers.append(numberOfNeuronsPerFCLayer)
        n_Epochs.append(numberOfEpochs)
        adamLearningRates.append(adamLearningRate)
        dropoutRates.append(dropoutRate)
        L2Rates.append(L2Rate)
        trainScores.append(trainScore)
        devScores.append(devScore)
        
        print('concluding trial ',trial)
        trial += 1
    else:
        print(f'redoing trial {trial}. Model was {model_size}MB.')
        failedTrial = util.createModelParametersDF([convFilters],[convAndPoolLayers],
                                              [numberOfFCLayers],[numberOfNeuronsPerFCLayer],[numberOfEpochs],
                                              [dropoutRate],[adamLearningRate],[L2Rate],[np.nan],[np.nan])
        display(failedTrial)
        
modelParametersDF = util.createModelParametersDF(n_convFilters,n_convAndPoolLayers,
                                            n_FCLayers,n_NeuronsPerFCLayers,n_Epochs,
                                            dropoutRates,adamLearningRates,L2Rates,trainScores,devScores)
display(modelParametersDF.sort_values(by='trainScore', ascending=False))
    





