import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow.keras as keras
import keras.backend as K
from keras.optimizers import Adam
%autosave 5


def loadData(dataset,split=0):
    if(split == 0):
        print("In non split")
        return tf.keras.preprocessing.image_dataset_from_directory(f"../Data/{dataset}",
                                                                   labels='inferred',shuffle=True,seed=51)
    else:
        print("In split")
        return tf.keras.preprocessing.image_dataset_from_directory(f"../Data/{dataset}",
                                                                   labels='inferred',shuffle=True,seed=51,
                                                            validation_split=split,subset='both')


#from https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d
def f1_score(y_true, y_pred): #taken from old keras source code 
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    recall = true_positives / (possible_positives + K.epsilon())
    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())
    return f1_val


def main():
    train = loadData("training")
    dev,test = loadData("testing",.5)

    possibleConvWidths = 
    
    model = keras.Sequential()
    for convAndPoolLayer in range(convAndPoolLayers):
        model.add(keras.layers.Conv2D(3,3, activation='relu',padding='same'))
        model.add(keras.layers.MaxPooling2D((3,3)))
        
    model.add(keras.layers.Flatten())
    
    for layer in range(convAndPoolLayers,layers - convAndPoolLayers + 1):
        if layer == layers - 1:
            activationFunction = 'sigmoid'
        else:
            activationFunction = 'relu'
        model.add(keras.layers.Dense(layers-layer,activation=activationFunction))
        if layer != layers - 1:
            model.add(keras.layers.Dropout(0.5))            

    model.compile(optimizer="adam",loss='binary_crossentropy', metrics=[f1_score])

    model.fit(train,epochs=100)

    print("train: ",model.evaluate(train))
    print("dev: ",model.evaluate(dev))
    
    


main()
