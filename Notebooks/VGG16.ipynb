{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839c7657-2caa-44cb-99c3-e83822b7726e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from IPython.display import display\n",
    "import json\n",
    "from os.path import exists\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from numpy.random import choice as choose\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../Src/\")\n",
    "import basicUtil\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe19ca5-8820-479e-a7dd-c574cd93e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image, label in dataset:\n",
    "        images.append(image.numpy())\n",
    "        labels.append(label.numpy())\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ae2794-81e3-4b2b-833c-ac5062d06864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTransferableModel(base_model,numberOfFCLayers, numberOfNeuronsPerFCLayer, dropoutRate, adamLearningRate, L2Rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    for layer in range(numberOfFCLayers):\n",
    "        if layer == numberOfFCLayers - 1:\n",
    "            model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "        else:\n",
    "            model.add(keras.layers.Dense(numberOfNeuronsPerFCLayer,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(L2Rate)))\n",
    "            model.add(keras.layers.Dropout(dropoutRate))\n",
    "            \n",
    "    adamOptimizer = keras.optimizers.legacy.Adam(learning_rate=adamLearningRate)       \n",
    "    model.compile(optimizer=\"adam\",loss='binary_crossentropy', metrics=f1_score)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84943d2e-0875-4f4e-8912-4c049947fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train = basicUtil.loadData(\"training\")\n",
    "    dev,test = basicUtil.loadData(\"testing\",.5)\n",
    "\n",
    "    train_images, train_labels = dataset_to_numpy(train)\n",
    "\n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=train_images[0].shape)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    train = preprocess_input(train)\n",
    "    dev = preprocess_input(dev)\n",
    "    test = preprocess_input(test)\n",
    "\n",
    "    possibleLayers = basicUtil.createRangeFromMidpoint(10,20)\n",
    "    possibleNeuronsPerLayer = basicUtil.createRangeFromMidpoint(10,20)\n",
    "    possibleEpochs = basicUtil.createRangeFromMidpoint(50,100)\n",
    "\n",
    "    dropoutCriticalPoints = (0,1)\n",
    "    adamLearningRateCriticalPoints = (1e-4,1e-2)\n",
    "    L2CriticalPoints = (1e-2,1e3) \n",
    "\n",
    "    n_FCLayers = []\n",
    "    n_NeuronsPerFCLayers = []\n",
    "    n_Epochs = []\n",
    "    dropoutRates = []\n",
    "    adamLearningRates = []\n",
    "    L2Rates = []\n",
    "    trainScores = []\n",
    "    devScores = []\n",
    "\n",
    "    trial = 0\n",
    "    bestDevScore = 0\n",
    "    \n",
    "    while trial < 100:\n",
    "        numberOfFCLayers = choose(possibleLayers)\n",
    "        numberOfNeuronsPerFCLayer = choose(possibleNeuronsPerLayer)\n",
    "\n",
    "        numberOfEpochs = choose(possibleEpochs)\n",
    "        \n",
    "        dropoutRate = generateDropoutRate(dropoutCriticalPoints[0],dropoutCriticalPoints[1])\n",
    "        adamLearningRate = generateAdamLearningRate(adamLearningRateCriticalPoints[0],adamLearningRateCriticalPoints[1])\n",
    "        L2Rate = generateL2(L2CriticalPoints[0],L2CriticalPoints[1])\n",
    "        model = createTransferableModel(base_model,numberOfFCLayers, numberOfNeuronsPerFCLayer, dropoutRate, adamLearningRate, L2Rate)\n",
    "        \n",
    "        model.fit(train,epochs=numberOfEpochs,verbose=0)\n",
    "\n",
    "        model_path = f'../Models/VGG16Trials/vgg16_model_{trial}.h5'\n",
    "        model.save(model_path)\n",
    "        model_size = os.path.getsize(model_path) / (1024 * 1024)\n",
    "        if model_size < 40:\n",
    "            print()\n",
    "            print('trainScore')\n",
    "            trainScore = model.evaluate(train)[1]\n",
    "            print('devScore')\n",
    "            devScore = model.evaluate(dev)[1]\n",
    "\n",
    "            if (devScore > 0.91) and (devScore > bestDevScore):\n",
    "                testScore = model.evaluate(test)[1]\n",
    "                model_path = f'../Models/best_fd_model_.h5'\n",
    "                model.save(model_path)\n",
    "                bestModelParams = {\n",
    "                    'n_FCLayers' : int(numberOfFCLayers),\n",
    "                    'n_NeuronsPerFCLayers' : int(numberOfNeuronsPerFCLayer),\n",
    "                    'n_Epochs' : int(numberOfEpochs),\n",
    "                    'dropoutRate' : dropoutRate,\n",
    "                    'adamLearningRates' : adamLearningRate,\n",
    "                    'L2Rates' : L2Rate,\n",
    "                    'modelSize' : model_size,\n",
    "                    'trainScore': trainScore,\n",
    "                    'devScore': devScore,\n",
    "                    'testScore': testScore\n",
    "                }\n",
    "                with open('../Models/best_vgg16_model_params.json', 'w') as f:\n",
    "                    json.dump(bestModelParams, f)\n",
    "                bestDevScore = devScore       \n",
    "\n",
    "            n_FCLayers.append(numberOfFCLayers)\n",
    "            n_NeuronsPerFCLayers.append(numberOfNeuronsPerFCLayer)\n",
    "            n_Epochs.append(numberOfEpochs)\n",
    "            \n",
    "            adamLearningRates.append(adamLearningRate)\n",
    "            dropoutRates.append(dropoutRate)\n",
    "            L2Rates.append(L2Rate)\n",
    "            trainScores.append(trainScore)\n",
    "            devScores.append(devScore)\n",
    "            \n",
    "            print('concluding trial ',trial)\n",
    "            trial += 1\n",
    "        else:\n",
    "            print(f'redoing trial {trial}. Model was {model_size}MB.')\n",
    "            failedTrial = createTransferModelParametersDF([numberOfFCLayers],[numberOfNeuronsPerFCLayer],[numberOfEpochs],\n",
    "                                                  [dropoutRate],[adamLearningRate],[L2Rate],[np.nan],[np.nan])\n",
    "            display(failedTrial)\n",
    "        \n",
    "            \n",
    "        if (trial % 10 == 9): \n",
    "            modelParametersDF = createTransferModelParametersDF(n_FCLayers,n_NeuronsPerFCLayers,n_Epochs,\n",
    "                                                    dropoutRates,adamLearningRates,L2Rates,trainScores,devScores)\n",
    "            modelParametersDF = modelParametersDF.sort_values(by='trainScore', ascending=False)\n",
    "            display(modelParametersDF)\n",
    "            \n",
    "            top5 = modelParametersDF[0:5]\n",
    "            possibleNumberOfFCLayers = basicUtil.getAdjustedRange(top5['n_FCLayers'])\n",
    "            possibleNumberOfNeuronsPerFCLayer = basicUtil.getAdjustedRange(top5['n_NeuronsPerFCLayers'])\n",
    "        \n",
    "            possibleNumberOfEpochs = basicUtil.getAdjustedRange(top5['n_Epochs'])\n",
    "            dropoutCriticalPoints = basicUtil.calculateCriticalPoints(top5['dropoutRate'])\n",
    "            adamLearningRateCriticalPoints = basicUtil.calculateLogisticCriticalPoints(top5['adamLearningRates'])\n",
    "            L2CriticalPoints = basicUtil.calculateLogisticCriticalPoints(top5['L2Rates'])\n",
    "\n",
    "            n_FCLayers = []\n",
    "            n_NeuronsPerFCLayers = []\n",
    "            n_Epochs = []\n",
    "            dropoutRates = []\n",
    "            adamLearningRates = []\n",
    "            L2Rates = []\n",
    "            trainScores = []\n",
    "            devScores = []\n",
    "\n",
    "            if bestDevScore > 0.91:\n",
    "                trial = 101\n",
    "                \n",
    "    basicUtil.displayFinalResults('../Models/best_fd_model_params.json')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99035138-e739-44d6-b63c-0856f1b70f27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In non split\n",
      "Found 2392 files belonging to 2 classes.\n",
      "In split\n",
      "Found 597 files belonging to 2 classes.\n",
      "Using 299 files for training.\n",
      "Using 298 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 01:11:54.960724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [2392]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-07-29 01:11:54.960884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [2392]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-07-29 01:11:54.967060: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (75,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main()\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m train \u001b[38;5;241m=\u001b[39m basicUtil\u001b[38;5;241m.\u001b[39mloadData(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m dev,test \u001b[38;5;241m=\u001b[39m basicUtil\u001b[38;5;241m.\u001b[39mloadData(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m.5\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m train_images, train_labels \u001b[38;5;241m=\u001b[39m dataset_to_numpy(train)\n\u001b[1;32m      7\u001b[0m base_model \u001b[38;5;241m=\u001b[39m VGG16(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39mtrain_images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mdataset_to_numpy\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      5\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(image\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m      6\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(label\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(images), np\u001b[38;5;241m.\u001b[39marray(labels)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (75,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
